{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83094007-7e44-4dd8-bf32-0ea472f2fc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Total Raw Rows: 431\n",
      "Unique Reviews: 431\n",
      "Categorizing reviews...\n",
      "Exploding dataset...\n",
      "\n",
      "SUCCESS! Created 'Frank_reviews_clean_exploded_final.csv' with 789 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FILE = 'CSV FILE NAME'\n",
    "FILE1 = ' '\n",
    "FILE2 = ' '\n",
    "OUTPUT_FILE = 'OUTPUT CSV FILE NAME'\n",
    "\n",
    "# Define Categories\n",
    "driver_bins = {\n",
    "    'Music & DJ': ['music', 'dj', 'sound', 'song', 'edm', 'hip hop', 'pop', 'techno', 'playlist', 'audio', 'speaker'],\n",
    "    'Drinks & Alcohol': ['drink', 'alcohol', 'cocktail', 'beer', 'bar', 'unli', 'free flow', 'water', 'weak', 'fake', 'strong', 'wine', 'champagne', 'shot', 'drunk', 'sober', 'tipsy', 'bartender'],\n",
    "    'Crowd & Atmosphere': ['crowd', 'packed', 'squeeze', 'people', 'vibe', 'atmosphere', 'smoke', 'hot', 'air', 'ventilation', 'space', 'dance floor', 'stuffy', 'busy', 'empty', 'dead', 'lively', 'fun', 'exciting'],\n",
    "    'Service & Staff': ['service', 'staff', 'pr', 'bouncer', 'security', 'rude', 'friendly', 'polite', 'attitude', 'guard', 'waiter', 'manager', 'reception', 'door'],\n",
    "    'Price & Entry': ['price', 'cost', 'entry', 'ticket', 'cover', 'expensive', 'cheap', 'worth', 'ntd', 'pay', 'money', 'scam', 'rip off', 'deal', 'free'],\n",
    "    'Facilities & Safety': ['toilet', 'bathroom', 'restroom', 'clean', 'dirty', 'safe', 'unsafe', 'thief', 'stole', 'lost', 'lockers', 'ac', 'smoking']\n",
    "}\n",
    "\n",
    "def categorize_review(text):\n",
    "    text = str(text).lower()\n",
    "    found_drivers = []\n",
    "    for driver, keywords in driver_bins.items():\n",
    "        if any(word in text for word in keywords):\n",
    "            found_drivers.append(driver)\n",
    "    return found_drivers if found_drivers else [\"Uncategorized\"]\n",
    "\n",
    "def parse_relative_date(row):\n",
    "    rel_str = str(row['relative_date']).lower().strip()\n",
    "    try:\n",
    "        scrape_date = pd.to_datetime(row['scrape_date'])\n",
    "    except:\n",
    "        scrape_date = datetime.now()\n",
    "\n",
    "    if rel_str in ['just now', 'unknown', 'nan', '']:\n",
    "        return scrape_date\n",
    "\n",
    "    if 'a ' in rel_str or 'an ' in rel_str: number = 1\n",
    "    else:\n",
    "        match = re.search(r'\\d+', rel_str)\n",
    "        number = int(match.group()) if match else 0\n",
    "\n",
    "    if 'minute' in rel_str: delta = timedelta(minutes=number)\n",
    "    elif 'hour' in rel_str: delta = timedelta(hours=number)\n",
    "    elif 'day' in rel_str: delta = timedelta(days=number)\n",
    "    elif 'week' in rel_str: delta = timedelta(weeks=number)\n",
    "    elif 'month' in rel_str: delta = timedelta(days=number * 30) \n",
    "    elif 'year' in rel_str: delta = timedelta(days=number * 365)\n",
    "    else: delta = timedelta(days=0)\n",
    "    return scrape_date - delta\n",
    "\n",
    "# --- EXECUTION ---\n",
    "print(\"Loading files...\")\n",
    "dfs = []\n",
    "try:\n",
    "    if os.path.exists(FILE1):\n",
    "        dfs.append(pd.read_csv(FILE1))\n",
    "\n",
    "    if os.path.exists(FILE2):\n",
    "        dfs.append(pd.read_csv(FILE2))\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"Error: No files found to process.\")\n",
    "        exit()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(FILE)\n",
    "    print(f\"Total Raw Rows: {len(df)}\")\n",
    "except Exception as e:\n",
    "    print(f'Error loading file: {e}')\n",
    "    raise \n",
    "\n",
    "# Remove Duplicates \n",
    "df = df.drop_duplicates(subset=['review_text', 'relative_date', 'rating'])\n",
    "print(f\"Unique Reviews: {len(df)}\")\n",
    "\n",
    "if 'scrape_date' not in df.columns:\n",
    "    df['scrape_date'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "df['real_date'] = df.apply(parse_relative_date, axis=1)\n",
    "\n",
    "# Clean Text\n",
    "df = df.dropna(subset=['review_text'])\n",
    "df = df[df['review_text'].str.strip() != '']\n",
    "\n",
    "# Fix Ratings\n",
    "df['rating'] = df['rating'].astype(str).str.replace(r'\\s*stars?', '', regex=True)\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Categorize\n",
    "print(\"Categorizing reviews...\")\n",
    "df['drivers_list'] = df['review_text'].apply(categorize_review)\n",
    "\n",
    "# Filter Useless Reviews\n",
    "df['word_count'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "df = df[ ~((df['drivers_list'].apply(lambda x: 'Uncategorized' in x)) & (df['word_count'] < 5)) ]\n",
    "\n",
    "# Explode\n",
    "print(\"Exploding dataset...\")\n",
    "df_exploded = df.explode('drivers_list').rename(columns={'drivers_list': 'category', 'real_date': 'review_date'})\n",
    "df_exploded.drop(columns='relative_date', inplace=True)\n",
    "df_exploded = df_exploded[df_exploded['category'] != 'Uncategorized']\n",
    "\n",
    "# Save\n",
    "df_exploded.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSUCCESS! Created '{OUTPUT_FILE}' with {len(df_exploded)} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
